{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 - Normalization and data types\n",
    "\n",
    "This first week is going to be a warm-up week where we conider different statistical tools data types.\n",
    "\n",
    "Lets first import the libraries that we are going to need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h0/m0sv2bl15y39_pvzt1zdwk5w0000gn/T/ipykernel_32894/1701976388.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dm22/lib/python3.7/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkde\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mqmc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_multivariate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontingency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dm22/lib/python3.7/site-packages/scipy/stats/qmc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_qmc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/dm22/lib/python3.7/site-packages/scipy/stats/_qmc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrng_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m from scipy.stats._sobol import (\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0minitialize_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_cscramble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fill_p_cumulative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fast_forward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0m_categorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize_direction_numbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MAXDIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MAXBIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dm22/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Sample statistics and normalization\n",
    "\n",
    "Let $X$ and $Y$ be two normal distributions of discrete variables with ($\\mu_X=25,\\sigma_X=5$) and ($\\mu_Y=60,\\sigma_Y=10$) that describe the *Age* and the *Weight* of a population. From $X$ and $Y$ sample the *Age* and the *Weight* of $n=500000$ individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.0 21.0\n",
      "41.0 55.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "# TODO: use np.random.normal to initialize X and Y and round() function for discretization of the data\n",
    "X = np.round(np.random.normal(25,5,500000))\n",
    "Y = np.round(np.random.normal(60,10,500000))\n",
    "\n",
    "print(X[1], X[17])\n",
    "print(Y[1], Y[5000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Find the mean, the median and the mode for $X,Y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{0: 2, 1: 1, 2: 2, 3: 0, 4: 1, 5: 0, 6: 0, 7: 1}\n",
      "2.0\n",
      "Mean: 25.005264\n",
      "Median: 25.0\n",
      "Mode: 25\n",
      "\n",
      "Mean: 60.002704\n",
      "Median: 60.0\n",
      "Mode: 60\n"
     ]
    }
   ],
   "source": [
    "def count_dictionary(X):\n",
    "    \"\"\"\n",
    "    Input: certain list of data   \n",
    "    Output: counts of list elements as a dictionary \n",
    "    Example: Input: [0,1,0,2,3,2,2] => Output: {0:2, 1:1, 2:3, 3:1}\n",
    "    \"\"\"\n",
    "    # TODO: the calculation process of counts\n",
    "    # We need counts also for later when we are computing the empirical PMF\n",
    "    X = list(X)\n",
    "    return {i : X.count(i) for i in range(int(np.max(X)) + 1)}\n",
    "\n",
    "print([0,0].count(0))\n",
    "print(count_dictionary([0,0,1,2,2,4,7]))\n",
    "\n",
    "def compute_mean(X):\n",
    "    \"\"\"\n",
    "    Input: certain list of data   \n",
    "    Output: mean of this list   \n",
    "    \"\"\"\n",
    "    # TODO: the calculation process of mean\n",
    "    return np.mean(X)\n",
    "\n",
    "print(compute_mean([1,1,4]))\n",
    "\n",
    "def compute_median(X):\n",
    "    \"\"\"\n",
    "    Input: certain list of data   \n",
    "    Output: median of this list\n",
    "    Tip:Note: If the number of data values is odd, returns the exact middle value. \n",
    "    If the number of data values is even, returns the average of the two middle values.   \n",
    "    \"\"\"\n",
    "    # TODO: the calculation process of median\n",
    "    X = list(X)\n",
    "    return np.median(X)\n",
    "\n",
    "def compute_mode(X):\n",
    "    \"\"\"\n",
    "    Input: certain list of data   \n",
    "    Output: element with highest frequency \n",
    "    Hint: You can use function count_dictionary   \n",
    "    \"\"\"\n",
    "    # TODO: the calculation process of mode  \n",
    "    X = list(X)\n",
    "    count_dict = count_dictionary(X)\n",
    "    mode = max(count_dict, key=count_dict.get)\n",
    "    return mode\n",
    "\n",
    "\n",
    "\n",
    "x_mean = compute_mean(X)\n",
    "#dictionary = count_dictionary(X)\n",
    "x_median = compute_median(X)\n",
    "x_mode = compute_mode(X)\n",
    "\n",
    "\n",
    "print(f\"Mean: {x_mean}\\nMedian: {x_median}\\nMode: {x_mode}\\n\" )\n",
    "\n",
    "y_mean = compute_mean(Y)\n",
    "y_median = compute_median(Y)\n",
    "y_mode = compute_mode(Y)\n",
    "\n",
    "print(f\"Mean: {y_mean}\\nMedian: {y_median}\\nMode: {y_mode}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Using the sampled data of a) find their:\\\n",
    "i) Probability Mass Function, ii) Expected Value and iii) Variance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to make our life a lot easier, we will compute the probability of each element\n",
    "# Because that will be useful for the next couple of tasks\n",
    "# NOTE: We can reuse the dictionary from earlier (Task A)\n",
    "\n",
    "\n",
    "def compute_pmf(X):\n",
    "    \"\"\"\n",
    "    Input: certain list of data   \n",
    "    Output: pmf as a dictionary \n",
    "    Example: Input: [0,1,0,2,3,2,2] => Output: {0:2/7, 1:1/7, 2:3/7, 3:1/7}\n",
    "    Hint: you can use count_dictionary function from a)\n",
    "    \"\"\"\n",
    "    # TODO: return pmf of X\n",
    "    count = count_dictionary(X)\n",
    "    for val in count:\n",
    "        count[val] = count[val]/len(X)\n",
    "    return count\n",
    "\n",
    "\n",
    "def compute_ev(X):\n",
    "    \"\"\"\n",
    "    Input: certain list of data   \n",
    "    Output: expected value of X \n",
    "    Hint: you can use compute_pmf function \n",
    "    \"\"\"\n",
    "    # TODO: return the expected value of X\n",
    "    pmf = compute_pmf(X)\n",
    "    ev = 0\n",
    "    for val, prob in pmf.items():\n",
    "        ev += val * prob\n",
    "    return ev\n",
    "\n",
    "\n",
    "def compute_variance(X):  \n",
    "    \"\"\"\n",
    "    Input: certain list of data   \n",
    "    Output: variance of X \n",
    "    Hint: you can use compute_pmf and compute_ev functions\n",
    "    \"\"\"\n",
    "    # TODO: return the variance of X\n",
    "    pmf = compute_pmf(X)\n",
    "    ev = compute_ev(X)\n",
    "    ev2 = compute_ev(X**2)\n",
    "    var = 0\n",
    "    for val, prob in ev.items():\n",
    "        var += prob * ()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "print(\"\\nFor X:\")\n",
    "x_pmf = compute_pmf(X)\n",
    "x_ev = compute_ev(X)\n",
    "print(f'Expected Value of X is {x_ev}')\n",
    "x_variance = compute_variance(X)\n",
    "print(f'Variance of X is {x_variance}')\n",
    "\n",
    "print(\"\\nFor Y:\")\n",
    "y_pmf = compute_pmf(Y)\n",
    "y_ev = compute_ev(Y)\n",
    "print(f'Expected Value of Y is {y_ev}')\n",
    "y_variance = compute_variance(Y)\n",
    "print(f'Variance of Y is {y_variance}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Suppose the only information we had is the sampled data $X$ and $Y$ for the *Age* and *Weight* respectively. Plot the distributions of $X$ and $Y$ and consider if the data seem to fit a normal distribution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# TODO: use plt.hist() and bins = len(np.unique()) in order to visualize the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** What is the probability of observing an age of 80 or higher?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HINT: To calculate the probability we have to use the probability density function of normal distribution for $X$, in range $[80,\\infty)$. Calculate the sample PDF and the expected PDF given that the distribution is normal with ($\\mu_Y=60,\\sigma_Y=10$). How close are these two values?\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # TODO: find the probability that age is >80 (PDF), then find the expected PDF of the normal distribution (μ=60,σ=10) and compare the results\n",
    "''' CDF of infty minus CDF of 80, so 1 - cdf(80)    - to find the pdf in an interval, take cdf of upper bound and sub cdf of lower bound'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Find the 2-dimensional mean $\\hat \\mu$ and the covariance matrix $\\widehat \\Sigma$ for these two variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute 2-Dimensional mean is the vector (E[X], E[Y])\n",
    "Z = np.c_[X, Y]\n",
    "n, d = Z.shape\n",
    "mu = np.mean(Z, axis =0, keepdims=True)\n",
    "cov = (Z-mu).T @ (Z-mu) /n\n",
    "\n",
    "# TODO: The diagonal of the Covariance matrix must equal the initial covariance values of X and Y. Check your results.\n",
    "print(\"Mean:\\n\", mu)\n",
    "print(\"Cov: \\n\", cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** Normalize the data with _range normalization_ to the range $[0, 1]$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**range normalization**:\n",
    "\n",
    "$x_i^{'} = \\frac{x_i-\\min_i{x_i}}{\\max_i{x_i} - \\min_i{x_i}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the range normalization: (x_i - min)/(max - min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g)** Normalize the data with _standard score normalization_ such that is has mean 0 and standard deviation 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**z-score**:\n",
    "\n",
    "$x_i^{'} = \\frac{x_i-\\hat{\\mu}}{\\hat{\\sigma}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: #  Compute the standard score normalization:, x_i = (x_i - mu)/(sigma)\n",
    "X_ssn = [[x- x_mean] / np.sqrt(x_variance) for x in X]\n",
    "Y_ssn = [[y - y_mean] / np.sqrt(y_variance) for y in Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Robustness\n",
    "Determine whether the following statements are true or false and explain why.\n",
    " - Mean is robust against outliers\n",
    " - Median is robust against outliers\n",
    " - Standard deviation is robust against outliers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Mean: No - the mean is calculated based on the value on the point\n",
    "\n",
    "Median: yes - it is based on position in the list\n",
    "\n",
    "Std dev: No, because it is similar to mean - it takes into account the values of the points, so it will be affected by the outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: More on robustness\n",
    "Provide an informal definition of when a measure is robust. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "-> A measure is robust when it is not affected too much by outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Independence analysis\n",
    "Please explain what the idea of independence analysis is using contingency tables; for which kind of data is this particularly relevant? \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "-> Determine if two categorical vars are ind. or if they are related. \n",
    "\n",
    "contingency table / count table - count all combinations of the values that the random vars can take. Make row counts and col counts.\n",
    "\n",
    "Independent: the distribution of one does not depend on the distribution of the other. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Contingency table and $\\chi^2$ statistics\n",
    "In the table below,  assuming that $X_1$ is discretized into three bins, as follows: $[-2, -0.5]$, $[-0.5, 0.5]$, and $[0.5, 2]$.\n",
    "\n",
    "![Table 3.11](graphics/3.11.png)\n",
    "\n",
    "Answer the following questions\n",
    "\n",
    "**a)** Construct the contingency table between the discretized $X_1$ and $X_2$ attributes, including the row and column counts.<br>\n",
    "**b)** Construct the expected table between the discretized $X_1$ and $X_2$ attributes.<br>\n",
    "**c)** Compute the $\\chi^2$ statistic between them.<br>\n",
    "**d)** Determine whether they are dependent or not at the 5% significance level. Use the $\\chi^2$ critical values from Table 3.10.\n",
    "\n",
    "![Table 3.10](graphics/3.10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "**a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (586528682.py, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/h0/m0sv2bl15y39_pvzt1zdwk5w0000gn/T/ipykernel_32894/586528682.py\"\u001b[0;36m, line \u001b[0;32m55\u001b[0m\n\u001b[0;31m    count_col[0] = b1_row[0] + b2_row[0] +\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "from scipy.stats.contingency import crosstab\n",
    "X_1 = [0.3, -0.3, 0.44, -0.60, 0.40, 1.20, -0.12, -1.60, 1.60, -1.32]\n",
    "X_2 = [\"a\", \"b\", \"a\", \"a\", \"a\", \"b\", \"a\", \"b\", \"b\", \"a\"]\n",
    "# For sanity's sake, use code to bin X_1\n",
    "# Converting everything to numbers allow us to index in them for easier computation\n",
    "X_tmp = []\n",
    "for x in X_1:\n",
    "    if x >= -2 and x <= -0.5:\n",
    "        X_tmp.append(0)\n",
    "    elif x >= -0.5 and x <= 0.5:\n",
    "            X_tmp.append(1)\n",
    "    elif x > 0.5:\n",
    "            X_tmp.append(2)\n",
    "X_1 = X_tmp\n",
    "X_2 = [0 if x == \"a\" else 1 for x in X_2]\n",
    "\n",
    "\n",
    "# Our table looks like\n",
    "## Bins: a b\n",
    "## bin1\n",
    "## bin2\n",
    "## bin3\n",
    "b1_row = [0, 0]\n",
    "b2_row = [0, 0]\n",
    "b3_row = [0, 0]\n",
    "count_row = [0, 0, 0] # THIS ONE is for column counts\n",
    "count_col = [0,0]\n",
    "c_table = [b1_row, b2_row, b3_row]\n",
    "# TODO: Compute contingency table c_table \n",
    "#stacked = np.row_stack((b1_row, b2_row, b3_row))\n",
    "#print(stacked)\n",
    "\n",
    "#contingency_table = crosstab(X_1, X_2)\n",
    "#print(contingency_table)\n",
    "\n",
    "zipped = list(zip(X_1,X_2))\n",
    "print(zipped)\n",
    "for i1 in range(3):\n",
    "    for i2 in range(2):\n",
    "        if i1 == 0:\n",
    "            b1_row[i2] += zipped.count((i1,i2))\n",
    "        elif i1 == 1:\n",
    "            b2_row[i2] += zipped.count((i1,i2))\n",
    "        else:\n",
    "            b3_row[i2] += zipped.count((i1,i2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "count_row[0] = sum(b1_row)\n",
    "count_row[1] = sum(b2_row)\n",
    "count_row[2] = sum(b3_row)\n",
    "\n",
    "for i in range(3):\n",
    "    count_col[i] = b1_row[i] + b2_row[i] + b3_row[i]\n",
    "\n",
    "\n",
    "print(f\"Our table before row counts: {c_table}\")   \n",
    "print(count_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "**b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h0/m0sv2bl15y39_pvzt1zdwk5w0000gn/T/ipykernel_32894/3565821316.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Now add row counts\n",
    "# Remember these are reference variables, so modifying these\n",
    "# will also modify our table\n",
    "\n",
    "# we assume that the values are independent, so to find the expected number of times we see e.g. \n",
    "# ac we have to multiply the prob of a by the prob of c\n",
    "\n",
    "\n",
    "# TODO: Compute expected table\n",
    "E = [[0, 0] for _ in range(3)]\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        E[i][j] = (c_table[i][2] * c_table[3][j])/ (len(X_1))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"The expected table is: {E}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "**c)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h0/m0sv2bl15y39_pvzt1zdwk5w0000gn/T/ipykernel_32894/1454877032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mChi_squared\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Chi_squared is: {Chi_squared}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# TODO: Compute Chi_squared\n",
    "Chi_squared = 0\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        Chi_squared += ((c_table[i][j] - E[i][j]) ** 2 / E[i][j])\n",
    "\n",
    "print(f\"Chi_squared is: {Chi_squared}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "**d)**\n",
    "\n",
    "-> critical chi squared is 5.991 from the table, as the degrees of freedom is 2 and we have a 5% significance level\n",
    "\n",
    "-> because our chi-squared is smaller than that (3 point something) we accept the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Working with Metrics\n",
    "\n",
    "Consider the following situation: \n",
    "\n",
    "We know some distances between data points: $d(p_1,p_2)=1$, $d(p_1,p_3)=2$, $d(p_3, p_4)=1$. \n",
    "We also know that $d$ is a metric. \n",
    "\n",
    "1. What do we know about the remaining distances?\n",
    "2. Do we need to compute further distances if we want to find the two points that are most similar to $p_1$? \n",
    "3. Can $p_4$ be closer to $p_2$ than $p_3$ is to $p_2$?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:**\n",
    "metric --> vi har triangle inequality\n",
    "\n",
    "    1. \n",
    "    p1->p3->p4, so d(p1,p4) <= 3\n",
    "    p4->p3 = 1, p3->p1 = 2, p1 -> p2 = 1   SO   d(p2, p4) <= 4\n",
    "    p3->p1 = 2, p1->p2 = 1    SO  d(p2, p3) <= 3\n",
    "\n",
    "    2.\n",
    "    We have to compute d(p1,p4), as we know that p2 is closer to p1 than p3, but we only have an upperbound on the distance from p4\n",
    "\n",
    "    3. \n",
    "    Yes, per the upper bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Exercises\n",
    "\n",
    "## Exercise 7: Mean absolute deviation \n",
    "Define a measure of deviation called _mean absolute deviation_ for a random variable $X$ as follows:\n",
    "\n",
    "$$\n",
    "\\frac{1}{n} \\sum_{i=1}^n |x_i - \\mu|\n",
    "$$\n",
    "\n",
    "Is this measure robust? Why or why not?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "-> not robust - we are using the mean, which is not robust "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Correlation\n",
    "\n",
    "Consider the table below. Assume that both the attributes $X$ and $Y$ are numeric, and the\n",
    "table represents the entire population. And we know that the correlation between $X$\n",
    "and $Y$ is zero.\n",
    "1. What can you infer about the values of $Y$? (Find a relationship between $a$, $b$ and $c$)\n",
    "2. If we know there is a missing row, what can we infer about it?\n",
    "\n",
    "|$X$ | $Y$ |\n",
    "|:---:|:---:|\n",
    "|$1$|$a$|\n",
    "|$0$|$b$|\n",
    "|$1$|$c$|\n",
    "|$0$|$a$|\n",
    "|$0$|$c$|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "    1. \n",
    "    probabilities of the values occuring based on the sample\n",
    "        P(a) = P(c) = 2/5 \n",
    "        P(c) = 1/5\n",
    "\n",
    "    2.\n",
    "    P(X = 0) = 3/5\n",
    "    P(X = 1) = 2/5\n",
    "\n",
    "    bc X, Y are independent, the probability of a row is the product of the values:\n",
    "        P(0,a) = 3/5 * 2/5 = 6/25\n",
    "        P(1,a) = 2/5 * 2/5 = 4/25\n",
    "        P(0,b) = 3/5 * 1/5 = 3/25\n",
    "        P(1,b) = 2/5 * 1/5 = 2/25\n",
    "        P(0,c) = 3/5 * 2/5 = 6/25\n",
    "        P(1,c) = 2/5 * 2/5 = 4/25\n",
    "    \n",
    "    so the probability of 0,a and 0,c are the highest for a new row based on the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9: 3-way contingency table\n",
    "\n",
    "Consider the 3-way contingency table for attributes $X$,$Y$,$Z$ shown in the table below.\n",
    "Compute the $\\chi^2$ metric for the correlation between $Y$ and $Z$. Are they dependent\n",
    "or independent at the 95% confidence level? See Table 3.10 above for $\\chi^2$ values.\n",
    "\n",
    "![Table 3.9](graphics/3.9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats.contingency\n",
    "from scipy.stats import chi2_contingency\n",
    "# TODO: Compute contingency using chi2_contingency\n",
    "xy = np.array([[40,25],[40,35]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10: Mixed data\n",
    "\n",
    "Consider the \"mixed\" data given in the table below. Here $X_1$ is a numeric attribute and\n",
    "$X_2$ is a categorical one. Assume that the domain of $X_2$ is given as $dom(X_2) = \\{a, b\\}$.\n",
    "Answer the following questions.\n",
    "\n",
    "**a)** What is the mean vector for this dataset?  \n",
    "**b)** What is the covariance matrix?  \n",
    "\n",
    "![Table 3.5](graphics/3.5.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine = np.array([[0.3,1,0],[-0.3,0,1],[0.44,1,0],[-0.6,1,0],[0.4,1,0],[1.2,0,1],[-0.12,1,0],[-0.16,0,1],[1.6,0,1],[-1.32,1,0]])\n",
    "# TODO: compute the mean vector\n",
    "mu = None\n",
    "print(\"mean vector:\\n\", mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = fine.shape\n",
    "# TODO: compute the covariance matrix\n",
    "cov = None\n",
    "\n",
    "print(f\"Cov: {cov}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.16 ('dm22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16 (default, Jan 17 2023, 09:28:58) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "37fc7d57704cfbdb47442f5b63d6c803e751954bcf1a6501b132e21f4cb1b0d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
